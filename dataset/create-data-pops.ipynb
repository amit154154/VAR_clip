{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceType": "datasetVersion",
     "sourceId": 9900229,
     "datasetId": 6081437,
     "databundleVersionId": 10156655
    }
   ],
   "dockerImageVersionId": 30787,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install diffusers"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install bitsandbytes\n"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "num_generate = 10000"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from diffusers import AutoPipelineForImage2Image\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "pipe = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "pipe = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-11-14T01:25:36.766377Z",
     "iopub.execute_input": "2024-11-14T01:25:36.767147Z",
     "iopub.status.idle": "2024-11-14T01:27:58.449684Z",
     "shell.execute_reply.started": "2024-11-14T01:25:36.767091Z",
     "shell.execute_reply": "2024-11-14T01:27:58.448796Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Function to load celebrity names from a text file\n",
    "def load_celebrities(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        celebrities = [line.strip() for line in file if line.strip()]\n",
    "    return celebrities\n",
    "\n",
    "# Load celebrity names from a text file\n",
    "celebrity_file = '/kaggle/input/real-pops/celebrities.txt'  # Replace with your file path\n",
    "celebrities = load_celebrities(celebrity_file)\n",
    "\n",
    "# Define the attributes with their options and inclusion probabilities\n",
    "attributes = {\n",
    "    'celebrity': {\n",
    "        'options': celebrities,\n",
    "        'probability': 0.8  # 80% chance to include\n",
    "    },\n",
    "    'skin_tone': {\n",
    "        'options': [\"light\", \"medium\", \"dark\", \"olive\", \"tan\"],\n",
    "        'probability': 0.9\n",
    "    },\n",
    "    'accessory': {\n",
    "        'options': [\"glasses\", \"hat\", \"headphones\", \"backpack\", \"jacket\", \"scarf\", \"watch\", \"necklace\"],\n",
    "        'probability': 0.5\n",
    "    },\n",
    "    'expression': {\n",
    "        'options': [\"smiling\", \"serious\", \"surprised\", \"happy\", \"angry\", \"winking\", \"laughing\"],\n",
    "        'probability': 0.6\n",
    "    },\n",
    "    'hairstyle': {\n",
    "        'options': [\"curly hair\", \"straight hair\", \"bald\", \"ponytail\", \"short hair\", \"long hair\", \"braided hair\", \"mohawk\"],\n",
    "        'probability': 0.5\n",
    "    },\n",
    "    # Additional attributes\n",
    "    'clothing_style': {\n",
    "        'options': [\"casual\", \"formal\", \"sporty\", \"vintage\", \"punk\", \"gothic\", \"hipster\", \"bohemian\"],\n",
    "        'probability': 0.5\n",
    "    },\n",
    "    'pose': {\n",
    "        'options': [\"standing\", \"sitting\", \"jumping\", \"dancing\", \"running\", \"saluting\", \"posing heroically\"],\n",
    "        'probability': 0.4\n",
    "    },\n",
    "    'theme': {\n",
    "        'options': [\"superhero\", \"musician\", \"athlete\", \"actor\", \"fantasy character\", \"robot\", \"alien\"],\n",
    "        'probability': 0.3\n",
    "    },\n",
    "    'holding_item': {\n",
    "        'options': [\"a sword\", \"a book\", \"a microphone\", \"a camera\", \"a guitar\", \"a shield\", \"a magic wand\"],\n",
    "        'probability': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_random_prompt():\n",
    "    selected_attributes = []\n",
    "    prompt_parts = []\n",
    "    \n",
    "    # Ensure at least one attribute is included\n",
    "    while not selected_attributes:\n",
    "        prompt_parts.clear()\n",
    "        for attr_name, attr_info in attributes.items():\n",
    "            if random.random() < attr_info['probability']:\n",
    "                value = random.choice(attr_info['options'])\n",
    "                # Format the attribute description based on the attribute name\n",
    "                if attr_name == 'celebrity':\n",
    "                    prompt_parts.append(f\"inspired by {value}\")\n",
    "                elif attr_name == 'skin_tone':\n",
    "                    prompt_parts.append(f\"with {value} skin\")\n",
    "                elif attr_name == 'accessory':\n",
    "                    prompt_parts.append(f\"wearing {value}\")\n",
    "                elif attr_name == 'expression':\n",
    "                    prompt_parts.append(f\"showing a {value} expression\")\n",
    "                elif attr_name == 'hairstyle':\n",
    "                    prompt_parts.append(f\"with {value}\")\n",
    "                elif attr_name == 'clothing_style':\n",
    "                    prompt_parts.append(f\"wearing {value} style clothing\")\n",
    "                elif attr_name == 'pose':\n",
    "                    prompt_parts.append(f\"in a {value} pose\")\n",
    "                elif attr_name == 'theme':\n",
    "                    prompt_parts.append(f\"themed as a {value}\")\n",
    "                elif attr_name == 'holding_item':\n",
    "                    prompt_parts.append(f\"holding {value}\")\n",
    "                selected_attributes.append(attr_name)\n",
    "        # If no attributes were selected, force inclusion of at least one attribute\n",
    "        if not selected_attributes:\n",
    "            attr_name = random.choice(list(attributes.keys()))\n",
    "            attr_info = attributes[attr_name]\n",
    "            value = random.choice(attr_info['options'])\n",
    "            # Format the attribute description\n",
    "            if attr_name == 'celebrity':\n",
    "                prompt_parts.append(f\"inspired by {value}\")\n",
    "            elif attr_name == 'skin_tone':\n",
    "                prompt_parts.append(f\"with {value} skin\")\n",
    "            # ... (handle other attributes similarly)\n",
    "            selected_attributes.append(attr_name)\n",
    "    \n",
    "    # Construct the final prompt\n",
    "    prompt_description = ', '.join(prompt_parts)\n",
    "    prompt = f\"A Funko Pop! figure {prompt_description}. Set on a white background.\"\n",
    "    return prompt\n",
    "\n",
    "# Generate sample prompts\n",
    "for _ in range(5):\n",
    "    print(generate_random_prompt())"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-11-14T01:47:09.783236Z",
     "iopub.execute_input": "2024-11-14T01:47:09.784045Z",
     "iopub.status.idle": "2024-11-14T01:47:09.805885Z",
     "shell.execute_reply.started": "2024-11-14T01:47:09.784004Z",
     "shell.execute_reply": "2024-11-14T01:47:09.805029Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_synthetic_dataset(input_folder, num_images, output_folder, pipe, generate_random_prompt):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset by creating images based on random prompts and initial images.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder (str): Path to the folder containing initial images.\n",
    "    - num_images (int): Number of synthetic images to generate.\n",
    "    - output_folder (str): Path to the folder where generated images will be saved.\n",
    "    - pipe: The image generation pipeline/model.\n",
    "    - generate_random_prompt (function): Function that generates a random prompt string.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Supported image file extensions\n",
    "    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')\n",
    "    \n",
    "    # List all image files in the input folder\n",
    "    input_images = [\n",
    "        os.path.join(input_folder, fname) for fname in os.listdir(input_folder)\n",
    "        if fname.lower().endswith(supported_extensions)\n",
    "    ]\n",
    "    \n",
    "    if not input_images:\n",
    "        raise ValueError(f\"No images found in the input folder: {input_folder}\")\n",
    "    \n",
    "    print(f\"Found {len(input_images)} images in {input_folder}. Starting generation of {num_images} images...\")\n",
    "    \n",
    "    # Path for the prompts log file\n",
    "    prompt_log_path = os.path.join(output_folder, \"generated_prompts.txt\")\n",
    "    \n",
    "    with open(prompt_log_path, \"w\") as log_file:\n",
    "        for i in tqdm(range(num_images), desc=\"Generating images\"):\n",
    "            try:\n",
    "                # Randomly select an initial image\n",
    "                init_image_path = random.choice(input_images)\n",
    "                init_image = Image.open(init_image_path).convert(\"RGB\").resize((512, 512))\n",
    "                \n",
    "                # Generate a random prompt\n",
    "                prompt = generate_random_prompt()\n",
    "                \n",
    "                # Randomly select guidance_scale between 0.3 and 0.5\n",
    "                guidance_scale = random.uniform(0.3, 0.5)\n",
    "                \n",
    "                # Generate the image using the pipeline\n",
    "                with torch.no_grad():\n",
    "                    generated = pipe(\n",
    "                        prompt=prompt,\n",
    "                        image=init_image,\n",
    "                        num_inference_steps=2,\n",
    "                        strength=1,\n",
    "                        guidance_scale=guidance_scale\n",
    "                    )\n",
    "                \n",
    "                if hasattr(generated, 'images'):\n",
    "                    image = generated.images[0]\n",
    "                else:\n",
    "                    raise AttributeError(\"The pipeline did not return an image.\")\n",
    "                \n",
    "                # Define a unique filename\n",
    "                output_filename = f\"synthetic_{i+1:05d}.png\"\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "                \n",
    "                # Save the generated image\n",
    "                image.save(output_path)\n",
    "                \n",
    "                # Log the filename and prompt in the text file\n",
    "                log_file.write(f\"{output_filename}: {prompt}\\n\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error generating image {i+1}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully generated {num_images} images in {output_folder}. Prompts saved in {prompt_log_path}.\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-11-14T01:52:25.226741Z",
     "iopub.execute_input": "2024-11-14T01:52:25.227206Z",
     "iopub.status.idle": "2024-11-14T01:52:25.242718Z",
     "shell.execute_reply.started": "2024-11-14T01:52:25.227160Z",
     "shell.execute_reply": "2024-11-14T01:52:25.241252Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "generate_synthetic_dataset(\"/kaggle/input/real-pops/real_hd_pops/real_hd_pops\",num_generate,\"/kaggle/working/pops_sdxl-turbo\",pipe,generate_random_prompt)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-11-14T01:52:25.784414Z",
     "iopub.execute_input": "2024-11-14T01:52:25.784819Z",
     "iopub.status.idle": "2024-11-14T01:52:36.655745Z",
     "shell.execute_reply.started": "2024-11-14T01:52:25.784781Z",
     "shell.execute_reply": "2024-11-14T01:52:36.654759Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
